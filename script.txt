ğŸš€ Tá»•ng quan Dá»± Ã¡n: Pipeline Dá»± Ä‘oÃ¡n Rá»§i ro Cá»• phiáº¿u Streaming Äa CÃ´ng ty
Dá»± Ã¡n nÃ y lÃ  má»™t há»‡ thá»‘ng MLOps (Váº­n hÃ nh MÃ¡y há»c) end-to-end, cÃ³ kháº£ nÄƒng thu tháº­p, xá»­ lÃ½, vÃ  dá»± Ä‘oÃ¡n rá»§i ro (giÃ¡ giáº£m máº¡nh) cho nhiá»u mÃ£ cá»• phiáº¿u cÃ¹ng lÃºc.

Há»‡ thá»‘ng Ä‘Æ°á»£c chia lÃ m hai luá»“ng (workflow) chÃ­nh cháº¡y song song:

Luá»“ng Batch (Huáº¥n luyá»‡n): ÄÆ°á»£c Ä‘iá»u phá»‘i bá»Ÿi Airflow. Luá»“ng nÃ y cháº¡y Ä‘á»‹nh ká»³ (hÃ ng ngÃ y) Ä‘á»ƒ thu tháº­p táº¥t cáº£ dá»¯ liá»‡u lá»‹ch sá»­ tá»« Kafka, lÆ°u vÃ o HDFS, sau Ä‘Ã³ huáº¥n luyá»‡n má»™t model Machine Learning má»›i vÃ  lÆ°u trá»¯ model Ä‘Ã³.

Luá»“ng Streaming (Dá»± Ä‘oÃ¡n): Cháº¡y liÃªn tá»¥c 24/7. Luá»“ng nÃ y thu tháº­p dá»¯ liá»‡u giÃ¡ má»›i nháº¥t, sá»­ dá»¥ng model Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n (tá»« Luá»“ng Batch) Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n rá»§i ro theo thá»i gian thá»±c, vÃ  lÆ°u káº¿t quáº£ vÃ o Redis Ä‘á»ƒ má»™t API cÃ³ thá»ƒ truy váº¥n.

1. ğŸ—ï¸ Háº¡ táº§ng & Äiá»u phá»‘i (docker-compose.yml & airflow/)
ÄÃ¢y lÃ  "xÆ°Æ¡ng sá»‘ng" vÃ  "bá»™ nÃ£o" láº­p lá»‹ch cá»§a dá»± Ã¡n.

docker-compose.yml:

Chá»©c nÄƒng: Äá»‹nh nghÄ©a vÃ  khá»Ÿi cháº¡y táº¥t cáº£ cÃ¡c service (container) trong dá»± Ã¡n. NÃ³ giá»‘ng nhÆ° báº£n thiáº¿t káº¿ cá»§a má»™t thÃ nh phá»‘, chá»‰ rÃµ cÃ¡c "tÃ²a nhÃ " (Spark, Kafka, HDFS, Redis, Python...) vÃ  "Ä‘Æ°á»ng" (network) ná»‘i chÃºng láº¡i.

TÆ°Æ¡ng tÃ¡c: NÃ³ Ä‘áº£m báº£o cÃ¡c service cÃ³ thá»ƒ "nÃ³i chuyá»‡n" vá»›i nhau (vÃ­ dá»¥: model-service cÃ³ thá»ƒ tÃ¬m tháº¥y kafka táº¡i Ä‘á»‹a chá»‰ kafka:9092). NÃ³ cÅ©ng mount (gáº¯n) cÃ¡c thÆ° má»¥c code (nhÆ° ./model_service) vÃ o bÃªn trong container, giÃºp cho train_job vÃ  model_service cÃ³ thá»ƒ chia sáº» chung cÃ¡c file model.

dags/spark_batch_dag.py:

Chá»©c nÄƒng: ÄÃ¢y lÃ  file "láº­p lá»‹ch" cá»§a Airflow. NÃ³ Ä‘á»‹nh nghÄ©a má»™t chuá»—i cÃ´ng viá»‡c (DAG).

TÆ°Æ¡ng tÃ¡c: NÃ³ ra lá»‡nh: "Má»—i ngÃ y má»™t láº§n, hÃ£y cháº¡y Task 1 (save_to_hdfs). Náº¿u nÃ³ thÃ nh cÃ´ng, hÃ£y cháº¡y Task 2 (train_model)." NÃ³ sá»­ dá»¥ng DockerOperator Ä‘á»ƒ thá»±c thi cÃ¡c job nÃ y.

2. ğŸŒŠ Luá»“ng Dá»¯ liá»‡u (Producer, Batch, Stream)
ÄÃ¢y lÃ  "há»‡ tuáº§n hoÃ n" cá»§a dá»± Ã¡n, mÃ´ táº£ cÃ¡ch dá»¯ liá»‡u di chuyá»ƒn.

kafka-producer/producer.py
Chá»©c nÄƒng: LÃ  nguá»“n dá»¯ liá»‡u (Data Ingestion) duy nháº¥t.

TÆ°Æ¡ng tÃ¡c:

Retry Logic: Khi khá»Ÿi Ä‘á»™ng, nÃ³ cÃ³ má»™t vÃ²ng láº·p "retry" (thá»­ láº¡i) Ä‘á»ƒ kiÃªn nháº«n chá» cho Ä‘áº¿n khi kafka sáºµn sÃ ng, giáº£i quyáº¿t lá»—i ECONNREFUSED.

Batch Send: Gá»­i 1 nÄƒm dá»¯ liá»‡u lá»‹ch sá»­ cá»§a nhiá»u cÃ´ng ty (vÃ­ dá»¥: AAPL, MSFT...) vÃ o topic Kafka historical_prices.

Stream Send: Báº¯t Ä‘áº§u má»™t vÃ²ng láº·p vÃ´ háº¡n, cá»© má»—i 60 (hoáº·c 5) giÃ¢y láº¡i láº¥y dá»¯ liá»‡u má»›i nháº¥t cá»§a cÃ¡c cÃ´ng ty Ä‘Ã³ vÃ  gá»­i vÃ o topic daily_prices.

Schema (Cáº¥u trÃºc): NÃ³ gá»­i cÃ¹ng má»™t schema (cáº¥u trÃºc) {timestamp, Ticker, Open, High, Low, Close, Volume} Ä‘áº¿n Cáº¢ HAI topic, Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n.

spark-jobs/save_to_hdfs_job.py (Cháº¡y bá»Ÿi Airflow)
Chá»©c nÄƒng: LÆ°u trá»¯ dá»¯ liá»‡u lá»‹ch sá»­ (Historian).

TÆ°Æ¡ng tÃ¡c: Khi Ä‘Æ°á»£c Airflow kÃ­ch hoáº¡t, nÃ³:

Káº¿t ná»‘i vá»›i Kafka vÃ  Ä‘á»c toÃ n bá»™ dá»¯ liá»‡u tá»« topic historical_prices.

Ãp dá»¥ng schema 7 cá»™t (bao gá»“m cáº£ Ticker).

LÆ°u táº¥t cáº£ dá»¯ liá»‡u nÃ y xuá»‘ng HDFS (hdfs://namenode:9000/data/raw/stock_data) dÆ°á»›i dáº¡ng file Parquet.

spark-jobs/train_job.py (Cháº¡y bá»Ÿi Airflow) - [2025-11-12, 14:57:25 UTC]]
Chá»©c nÄƒng: Huáº¥n luyá»‡n model (Model Trainer).

TÆ°Æ¡ng tÃ¡c:

Cháº¡y sau khi save_to_hdfs thÃ nh cÃ´ng.

Äá»c file Parquet tá»« HDFS.

TÃ­nh toÃ¡n Feature (Quan trá»ng): Thá»±c hiá»‡n groupby('Ticker').apply(...) Ä‘á»ƒ tÃ­nh cÃ¡c feature (nhÆ° Volatility_Cluster) riÃªng biá»‡t cho tá»«ng cÃ´ng ty.

MÃ£ hÃ³a Feature (Quan trá»ng): Thá»±c hiá»‡n "One-Hot Encoding" Ä‘á»ƒ biáº¿n cÃ¡c cá»™t chá»¯ (nhÆ° AAPL, MSFT) thÃ nh cÃ¡c cá»™t sá»‘ (nhÆ° Ticker_AAPL: 1, Ticker_MSFT: 0).

Huáº¥n luyá»‡n RandomForestClassifier trÃªn bá»™ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½.

LÆ°u 2 file quan trá»ng vÃ o thÆ° má»¥c /models (tá»©c lÃ  model_service/): risk_model.joblib (model) vÃ  model_features.json (danh sÃ¡ch cÃ¡c cá»™t Ä‘Ã£ mÃ£ hÃ³a).

3. âš¡ Phá»¥c vá»¥ & Dá»± Ä‘oÃ¡n (Serving & Prediction)
ÄÃ¢y lÃ  "máº·t tiá»n" cá»§a dá»± Ã¡n, nÆ¡i model Ä‘Æ°á»£c sá»­ dá»¥ng.

model_service/serve.py
Chá»©c nÄƒng: Bá»™ nÃ£o dá»± Ä‘oÃ¡n thá»i gian thá»±c (Real-time Brain).

TÆ°Æ¡ng tÃ¡c (Khi khá»Ÿi Ä‘á»™ng):

Táº£i model tá»« risk_model.joblib.

Táº£i danh sÃ¡ch feature tá»« model_features.json (Ä‘á»ƒ biáº¿t cÃ¡ch mÃ£ hÃ³a One-Hot).

Káº¿t ná»‘i Kafka vÃ  láº¯ng nghe topic daily_prices.

Káº¿t ná»‘i Redis.

TÆ°Æ¡ng tÃ¡c (Khi cháº¡y):

Nháº­n má»™t tin nháº¯n (vÃ­ dá»¥: MSFT) tá»« daily_prices.

TÃ¬m "cá»­a sá»•" (window) dá»¯ liá»‡u cá»§a MSFT trong má»™t dict (tá»« Ä‘iá»ƒn); náº¿u chÆ°a cÃ³, táº¡o má»™t cá»­a sá»• má»›i.

Khi cá»­a sá»• cá»§a MSFT cÃ³ Ä‘á»§ 22 tin nháº¯n, nÃ³ báº¯t Ä‘áº§u tÃ­nh feature (giá»‘ng há»‡t train_job).

NÃ³ thá»±c hiá»‡n One-Hot Encoding (biáº¿n MSFT thÃ nh Ticker_MSFT: 1...) dá»±a trÃªn file model_features.json.

NÃ³ Ä‘Æ°a cÃ¡c feature nÃ y vÃ o model Ä‘á»ƒ dá»± Ä‘oÃ¡n (vÃ­ dá»¥: {"Ticker": "MSFT", "prediction": 0, "probability": 0.07}).

NÃ³ gá»­i káº¿t quáº£ dá»± Ä‘oÃ¡n nÃ y vÃ o topic predictions.

NÃ³ cÅ©ng cung cáº¥p API (GET /latest_prediction vÃ  GET /recent_predictions) cho UI.

prediction_saver/saver.py
Chá»©c nÄƒng: LÆ°u trá»¯ dá»± Ä‘oÃ¡n (Prediction Scribe).

TÆ°Æ¡ng tÃ¡c:

Káº¿t ná»‘i Kafka (vá»›i code retry) vÃ  láº¯ng nghe topic predictions.

Khi nháº­n Ä‘Æ°á»£c má»™t JSON dá»± Ä‘oÃ¡n tá»« model_service, nÃ³ sáº½ lÆ°u JSON Ä‘Ã³ vÃ o Redis (cáº£ hai: ghi Ä‘Ã¨ latest_prediction vÃ  Ä‘áº©y vÃ o danh sÃ¡ch recent_predictions_list).

ÄÃ¢y lÃ  service cung cáº¥p dá»¯ liá»‡u cho API GET /latest_prediction vÃ  GET /recent_predictions.