[2025-11-12T03:46:48.398+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:46:48.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:46:48.402+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:46:48.401+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:46:48.431+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:46:48.474+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:46:48.474+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:46:48.540+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:46:48.539+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:46:48.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.176 seconds
[2025-11-12T03:47:19.417+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:19.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:47:19.420+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:19.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:19.459+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:19.797+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:19.796+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:47:19.828+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:19.828+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:47:19.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.466 seconds
[2025-11-12T03:47:50.582+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:50.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:47:50.588+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:50.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:50.626+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:47:50.668+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:50.668+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:47:50.709+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:47:50.708+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:47:50.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.164 seconds
[2025-11-12T03:48:21.553+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:21.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:48:21.557+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:21.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:21.594+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:21.634+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:21.633+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:48:21.666+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:21.666+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:48:21.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.154 seconds
[2025-11-12T03:48:52.029+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:52.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:48:52.035+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:52.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:52.135+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:48:52.206+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:52.206+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:48:52.378+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:48:52.377+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:48:52.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.391 seconds
[2025-11-12T03:49:22.615+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:22.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:49:22.620+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:22.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:22.666+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:22.733+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:22.732+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:49:22.792+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:22.792+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:49:22.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.226 seconds
[2025-11-12T03:49:53.193+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:53.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:49:53.196+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:53.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:53.228+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:49:53.292+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:53.292+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:49:53.326+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:49:53.325+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:49:53.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.175 seconds
[2025-11-12T03:50:23.558+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:23.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:50:23.563+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:23.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:23.607+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:23.630+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:23.630+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:50:23.676+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:23.675+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:50:23.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.155 seconds
[2025-11-12T03:50:53.784+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:53.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:50:53.788+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:53.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:53.824+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:50:54.058+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:54.057+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:50:54.094+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:50:54.093+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:50:54.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.350 seconds
[2025-11-12T03:51:24.401+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:24.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:51:24.408+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:24.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:24.451+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:24.490+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:24.489+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:51:24.526+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:24.526+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:51:24.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.162 seconds
[2025-11-12T03:51:54.729+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:54.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:51:54.733+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:54.732+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:54.780+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:51:54.819+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:54.818+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:51:54.857+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:51:54.857+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:51:54.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.173 seconds
[2025-11-12T03:52:24.998+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:24.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:52:25.001+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:25.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:25.036+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:25.073+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:25.072+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:52:25.111+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:25.111+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:52:25.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.148 seconds
[2025-11-12T03:52:55.219+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:55.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:52:55.224+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:55.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:55.262+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:52:55.313+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:55.312+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:52:55.363+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:52:55.363+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:52:55.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.187 seconds
[2025-11-12T03:53:25.667+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:25.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:53:25.670+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:25.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:25.722+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:25.774+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:25.773+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:53:25.828+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:25.827+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:53:25.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.201 seconds
[2025-11-12T03:53:56.506+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:56.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:53:56.517+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:56.516+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:56.570+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:53:56.631+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:56.631+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:53:56.677+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:53:56.677+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:53:56.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.222 seconds
[2025-11-12T03:54:27.043+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:27.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:54:27.048+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:27.047+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:27.098+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:27.144+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:27.143+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:54:27.187+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:27.186+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:54:27.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.181 seconds
[2025-11-12T03:54:57.328+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:57.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:54:57.351+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:57.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:57.397+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:54:57.443+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:57.442+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:54:57.490+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:54:57.489+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:54:57.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.230 seconds
[2025-11-12T03:55:27.784+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:27.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:55:27.789+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:27.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:27.832+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:27.881+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:27.881+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:55:27.928+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:27.927+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:55:27.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.220 seconds
[2025-11-12T03:55:58.077+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:58.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:55:58.081+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:58.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:58.115+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:55:58.175+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:58.175+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:55:58.213+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:55:58.213+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:55:58.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.205 seconds
[2025-11-12T03:56:28.761+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:28.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:56:28.766+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:28.765+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:28.804+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:28.845+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:28.845+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:56:28.884+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:28.884+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:56:28.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.161 seconds
[2025-11-12T03:56:59.610+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:59.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:56:59.615+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:59.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:59.646+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:56:59.685+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:59.685+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:56:59.725+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:56:59.724+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:56:59.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.166 seconds
[2025-11-12T03:57:30.583+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:57:30.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:57:30.587+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:57:30.587+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:57:30.626+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:57:30.674+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:57:30.674+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:57:30.720+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:57:30.720+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:57:30.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.206 seconds
[2025-11-12T03:58:01.893+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:01.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:58:01.898+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:01.897+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:01.975+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:02.021+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:02.020+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:58:02.060+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:02.059+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:58:02.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.208 seconds
[2025-11-12T03:58:32.874+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:32.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:58:32.879+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:32.879+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:32.920+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:58:32.975+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:32.974+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:58:33.020+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:58:33.019+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:58:33.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.185 seconds
[2025-11-12T03:59:03.978+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:03.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:59:03.983+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:03.983+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:04.027+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:04.066+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:04.066+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:59:04.105+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:04.104+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:59:04.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.203 seconds
[2025-11-12T03:59:34.262+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:34.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T03:59:34.266+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:34.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:34.304+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T03:59:34.348+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:34.347+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T03:59:34.388+0000] {logging_mixin.py:188} INFO - [2025-11-12T03:59:34.388+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T03:59:34.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.198 seconds
[2025-11-12T04:00:05.062+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:05.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:00:05.066+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:05.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:05.103+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:05.177+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:05.177+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:00:05.217+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:05.217+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:00:05.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.193 seconds
[2025-11-12T04:00:35.889+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:35.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:00:35.895+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:35.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:35.925+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:00:35.964+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:35.964+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:00:36.001+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:00:36.001+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:00:36.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.178 seconds
[2025-11-12T04:01:06.521+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:06.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:01:06.527+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:06.526+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:06.574+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:06.619+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:06.618+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:01:06.665+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:06.665+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:01:06.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.180 seconds
[2025-11-12T04:01:37.268+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:37.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:01:37.271+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:37.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:37.300+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:01:37.340+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:37.339+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:01:37.379+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:01:37.379+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:01:37.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.148 seconds
[2025-11-12T04:02:08.194+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:08.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:02:08.198+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:08.198+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:08.242+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:08.289+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:08.289+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:02:08.334+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:08.333+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:02:08.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.183 seconds
[2025-11-12T04:02:38.935+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:38.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:02:38.941+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:38.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:38.983+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:02:39.027+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:39.027+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:02:39.071+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:02:39.070+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:02:39.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.197 seconds
[2025-11-12T04:03:09.808+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:09.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:03:09.813+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:09.813+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:09.858+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:09.901+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:09.901+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:03:09.944+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:09.944+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:03:09.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.265 seconds
[2025-11-12T04:03:39.931+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:39.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:03:39.935+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:39.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:39.968+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:03:40.013+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:40.013+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:03:40.053+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:03:40.052+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:03:40.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.196 seconds
[2025-11-12T04:04:10.745+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:10.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:04:10.749+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:10.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:10.785+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:10.834+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:10.833+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:04:10.882+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:10.881+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:04:10.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.212 seconds
[2025-11-12T04:04:41.534+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:41.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:04:41.538+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:41.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:41.571+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:04:41.612+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:41.611+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:04:41.650+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:04:41.649+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:04:41.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.182 seconds
[2025-11-12T04:05:12.309+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:12.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:05:12.312+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:12.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:12.351+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:12.394+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:12.393+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:05:12.433+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:12.433+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:05:12.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.195 seconds
[2025-11-12T04:05:43.121+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:43.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:05:43.126+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:43.125+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:43.167+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:05:43.221+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:43.221+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:05:43.264+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:05:43.263+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:05:43.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.217 seconds
[2025-11-12T04:06:13.911+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:13.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:06:13.915+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:13.914+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:13.953+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:13.999+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:13.999+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:06:14.038+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:14.037+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:06:14.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.199 seconds
[2025-11-12T04:06:44.571+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:44.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:06:44.575+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:44.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:44.613+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:06:44.661+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:44.660+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:06:44.701+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:06:44.701+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:06:44.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.203 seconds
[2025-11-12T04:07:15.437+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:15.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:07:15.441+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:15.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:15.497+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:15.545+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:15.545+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:07:15.103+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:15.102+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:07:15.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.193 seconds
[2025-11-12T04:07:45.416+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:45.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:07:45.424+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:45.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:45.479+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:07:45.527+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:45.526+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:07:45.567+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:07:45.567+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:07:45.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.222 seconds
[2025-11-12T04:08:16.215+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:16.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:08:16.219+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:16.219+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:16.260+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:16.306+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:16.306+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:08:16.348+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:16.347+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:08:16.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.205 seconds
[2025-11-12T04:08:47.171+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:47.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:08:47.175+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:47.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:47.209+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:08:47.249+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:47.248+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:08:47.285+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:08:47.285+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:08:47.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.183 seconds
[2025-11-12T04:09:17.915+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:17.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:09:17.919+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:17.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:17.958+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:18.002+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:18.002+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:09:18.041+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:18.041+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:09:18.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.170 seconds
[2025-11-12T04:09:48.617+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:48.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:09:48.621+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:48.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:48.666+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:09:48.717+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:48.717+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:09:48.783+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:09:48.782+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:09:48.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.247 seconds
[2025-11-12T04:10:19.390+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:19.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:10:19.394+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:19.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:19.434+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:19.485+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:19.484+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:10:19.532+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:19.532+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:10:19.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.180 seconds
[2025-11-12T04:10:50.162+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:50.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:10:50.167+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:50.166+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:50.207+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:10:50.279+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:50.278+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:10:50.331+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:10:50.331+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:10:50.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.235 seconds
[2025-11-12T04:11:20.743+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:20.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:11:20.747+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:20.747+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:20.785+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:20.831+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:20.831+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:11:20.867+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:20.867+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:11:20.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.164 seconds
[2025-11-12T04:11:51.662+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:51.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:11:51.667+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:51.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:51.699+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:11:51.742+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:51.742+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:11:51.785+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:11:51.784+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:11:51.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.161 seconds
[2025-11-12T04:12:22.403+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:22.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:12:22.406+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:22.406+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:22.438+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:22.478+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:22.478+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:12:22.521+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:22.520+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:12:22.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.187 seconds
[2025-11-12T04:12:53.443+0000] {processor.py:161} INFO - Started process (PID=438) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:53.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:12:53.447+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:53.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:53.484+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:12:53.531+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:53.531+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:12:53.573+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:12:53.573+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:12:53.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.167 seconds
[2025-11-12T04:13:24.354+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:24.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:13:24.358+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:24.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:24.392+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:24.440+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:24.440+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:13:24.521+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:24.521+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:13:24.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.236 seconds
[2025-11-12T04:13:55.507+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:55.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:13:55.512+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:55.511+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:55.551+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:13:55.598+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:55.597+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:13:55.640+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:13:55.639+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:13:55.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.204 seconds
[2025-11-12T04:14:26.232+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:26.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:14:26.236+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:26.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:26.271+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:26.311+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:26.311+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:14:26.351+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:26.351+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:14:26.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.189 seconds
[2025-11-12T04:14:57.312+0000] {processor.py:161} INFO - Started process (PID=458) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:57.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:14:57.316+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:57.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:57.361+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:14:57.410+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:57.410+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:14:57.453+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:14:57.452+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:14:57.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.218 seconds
[2025-11-12T04:15:28.308+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:28.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:15:28.313+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:28.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:28.352+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:28.397+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:28.396+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:15:28.439+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:28.439+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:15:28.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.168 seconds
[2025-11-12T04:15:59.365+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:59.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:15:59.370+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:59.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:59.418+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:15:59.460+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:59.460+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:15:59.494+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:15:59.494+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:15:59.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.169 seconds
[2025-11-12T04:16:30.046+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:16:30.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:16:30.051+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:16:30.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:16:30.091+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:16:30.144+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:16:30.144+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:16:30.189+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:16:30.189+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:16:30.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.220 seconds
[2025-11-12T04:17:00.943+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:00.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:17:00.947+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:00.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:00.983+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:01.031+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:01.030+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:17:01.074+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:01.074+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:17:01.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.182 seconds
[2025-11-12T04:17:31.675+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:31.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:17:31.679+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:31.678+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:31.718+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:17:31.767+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:31.766+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:17:31.809+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:17:31.809+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:17:31.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.209 seconds
[2025-11-12T04:18:02.500+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:02.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:18:02.503+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:02.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:02.537+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:02.579+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:02.579+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:18:02.621+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:02.621+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:18:02.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.184 seconds
[2025-11-12T04:18:33.189+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:33.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:18:33.194+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:33.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:33.237+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:18:33.311+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:33.310+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:18:33.361+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:18:33.360+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:18:33.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.244 seconds
[2025-11-12T04:19:04.015+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:04.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:19:04.019+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:04.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:04.055+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:04.102+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:04.101+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:19:04.139+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:04.138+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:19:04.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.165 seconds
[2025-11-12T04:19:34.984+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:35.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:19:35.059+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:35.058+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:35.155+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:19:35.197+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:35.197+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:19:35.231+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:19:35.231+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:19:35.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.283 seconds
[2025-11-12T04:20:06.171+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:20:06.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:20:06.179+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:20:06.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:20:06.261+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:20:06.346+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:20:06.344+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:20:06.441+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:20:06.440+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:20:06.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.353 seconds
[2025-11-12T04:22:42.751+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:22:42.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:22:42.755+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:22:42.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:22:42.800+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:22:42.836+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:22:42.836+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:22:42.889+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:22:42.889+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:22:42.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.204 seconds
[2025-11-12T04:23:13.362+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:13.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:23:13.367+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:13.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:13.411+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:13.723+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:13.723+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:23:13.759+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:13.759+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:23:13.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.438 seconds
[2025-11-12T04:23:44.135+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:44.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:23:44.139+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:44.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:44.179+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:23:44.223+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:44.223+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:23:44.268+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:23:44.267+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:23:44.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.202 seconds
[2025-11-12T04:24:14.585+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:14.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:24:14.590+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:14.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:14.620+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:14.659+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:14.659+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:24:14.697+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:14.697+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:24:14.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.155 seconds
[2025-11-12T04:24:45.742+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:45.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:24:45.746+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:45.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:45.777+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:24:45.826+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:45.826+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:24:45.866+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:24:45.865+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:24:45.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.171 seconds
[2025-11-12T04:25:16.394+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:16.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:16.397+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:16.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:16.435+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:16.484+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:16.484+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:25:16.530+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:16.529+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:25:16.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.200 seconds
[2025-11-12T04:25:41.195+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:41.199+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.253+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.304+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.303+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:25:41.358+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.357+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:25:41.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.218 seconds
[2025-11-12T04:25:41.488+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:41.492+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.529+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:41.575+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.574+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:25:41.621+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:41.620+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:25:41.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.182 seconds
[2025-11-12T04:25:42.550+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:42.554+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:42.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.616+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:42.607+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:42.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.110 seconds
[2025-11-12T04:25:42.782+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:42.786+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:42.785+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.813+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:42.807+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:42.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:42.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.094 seconds
[2025-11-12T04:25:54.284+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:54.288+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.287+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.336+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.328+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:54.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.123 seconds
[2025-11-12T04:25:54.478+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:54.482+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.513+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.506+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:54.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.101 seconds
[2025-11-12T04:25:54.637+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:54.641+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.673+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.665+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:54.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.070 seconds
[2025-11-12T04:25:54.768+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:54.772+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.805+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.797+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:54.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T04:25:54.907+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:54.910+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.939+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:54.933+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:54.940+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:54.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.068 seconds
[2025-11-12T04:25:55.029+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.032+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.064+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.058+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T04:25:55.170+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.172+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.174+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.206+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.200+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T04:25:55.303+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.307+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.339+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.331+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.069 seconds
[2025-11-12T04:25:55.434+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.438+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.468+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.462+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.469+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.069 seconds
[2025-11-12T04:25:55.560+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.563+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.593+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.587+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.594+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.068 seconds
[2025-11-12T04:25:55.685+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.688+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.718+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.711+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.069 seconds
[2025-11-12T04:25:55.809+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.812+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.840+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.833+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.842+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.064 seconds
[2025-11-12T04:25:55.932+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:55.935+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.935+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:55.968+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:55.959+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:55.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:56.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T04:25:58.980+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:58.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:58.984+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:58.983+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.027+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.020+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.111 seconds
[2025-11-12T04:25:59.151+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.154+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.154+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.193+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.185+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.194+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T04:25:59.282+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.286+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.320+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.312+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T04:25:59.411+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.414+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.414+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.444+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.438+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.067 seconds
[2025-11-12T04:25:59.539+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.543+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.573+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.567+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.099 seconds
[2025-11-12T04:25:59.700+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.704+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.737+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.730+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T04:25:59.853+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:25:59.857+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.856+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.888+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:25:59.882+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:25:59.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:25:59.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.095 seconds
[2025-11-12T04:26:00.003+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:26:00.007+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.036+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.029+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:26:00.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.107 seconds
[2025-11-12T04:26:00.181+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:26:00.184+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.184+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.217+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.210+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:26:00.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T04:26:00.309+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:26:00.312+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.348+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.340+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:26:00.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T04:26:00.446+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:26:00.449+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.480+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:00.474+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:26:00.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:00.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T04:26:44.555+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:44.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:26:44.563+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:44.561+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:44.599+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:26:44.591+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:26:44.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:26:44.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T04:27:15.232+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:15.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:27:15.238+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:27:15.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:15.270+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:27:15.264+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:27:15.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:15.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T04:27:46.350+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:46.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:27:46.353+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:27:46.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:46.384+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:27:46.376+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:27:46.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:27:46.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.066 seconds
[2025-11-12T04:28:16.981+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:16.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:16.985+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:16.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:17.016+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:17.008+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:17.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:17.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.098 seconds
[2025-11-12T04:28:18.143+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.147+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.146+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.192+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.184+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T04:28:18.282+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.285+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.316+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.309+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.095 seconds
[2025-11-12T04:28:18.445+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.448+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.448+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.482+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.475+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.105 seconds
[2025-11-12T04:28:18.611+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.614+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.647+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.639+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T04:28:18.753+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.758+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.795+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.787+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.110 seconds
[2025-11-12T04:28:18.917+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:28:18.921+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.948+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:28:18.942+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:28:18.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:28:18.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.064 seconds
[2025-11-12T04:29:03.355+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:03.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:29:03.358+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:29:03.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:03.385+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:29:03.379+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:29:03.387+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:03.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.063 seconds
[2025-11-12T04:29:33.652+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:33.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:29:33.656+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:29:33.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:33.692+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:29:33.684+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:29:33.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:29:33.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.115 seconds
[2025-11-12T04:30:04.552+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:04.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:30:04.558+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:30:04.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:04.601+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:30:04.592+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:30:04.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:04.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.127 seconds
[2025-11-12T04:30:35.188+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:35.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:30:35.192+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:30:35.191+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:35.223+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:30:35.215+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:30:35.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:30:35.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.103 seconds
[2025-11-12T04:31:06.030+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:06.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:31:06.034+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:06.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:06.076+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:06.067+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:31:06.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:06.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T04:31:12.113+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:31:12.117+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:12.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.160+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:12.153+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:31:12.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.108 seconds
[2025-11-12T04:31:12.289+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:31:12.292+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:12.291+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.324+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:12.316+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:31:12.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:12.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T04:31:43.191+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:43.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:31:43.195+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:43.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:43.227+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:31:43.221+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:31:43.228+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:31:43.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.068 seconds
[2025-11-12T04:35:16.872+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:16.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:35:16.875+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:35:16.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:16.909+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:35:16.898+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:35:16.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:16.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T04:35:47.730+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:47.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:35:47.735+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:35:47.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:47.778+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:35:47.771+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:35:47.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:35:47.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.092 seconds
[2025-11-12T04:36:18.425+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:18.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:36:18.429+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:36:18.428+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:18.460+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:36:18.454+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:36:18.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:18.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T04:36:49.485+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:49.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:36:49.490+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:36:49.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:49.531+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:36:49.522+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:36:49.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:36:49.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.092 seconds
[2025-11-12T04:37:20.129+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:20.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:37:20.135+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:37:20.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:20.172+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:37:20.162+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'image_pull_policy': 'Never'}
[2025-11-12T04:37:20.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:20.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.117 seconds
[2025-11-12T04:37:32.345+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:32.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:37:32.350+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:37:32.349+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:32.404+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:37:32.395+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:37:32.405+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:37:32.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.106 seconds
[2025-11-12T04:38:28.241+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:28.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:38:28.247+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:38:28.246+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:28.299+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:38:28.288+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:38:28.301+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:28.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.100 seconds
[2025-11-12T04:38:58.939+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:58.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:38:58.944+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:38:58.943+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:58.981+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:38:58.973+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:38:58.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:38:59.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.091 seconds
[2025-11-12T04:39:29.791+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:39:29.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:39:29.795+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:39:29.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:39:29.827+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:39:29.819+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:39:29.828+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:39:29.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.103 seconds
[2025-11-12T04:40:00.130+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:00.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:00.136+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:00.135+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:00.171+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:00.163+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 30, in <module>
    save_to_hdfs = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: save_to_hdfs). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:00.172+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:00.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.109 seconds
[2025-11-12T04:40:03.236+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.240+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.291+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.282+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:03.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.122 seconds
[2025-11-12T04:40:03.410+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.413+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.447+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.440+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:03.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T04:40:03.541+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.544+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.574+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.568+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:03.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.067 seconds
[2025-11-12T04:40:03.659+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.662+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.692+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.685+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:03.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.066 seconds
[2025-11-12T04:40:03.783+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.786+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.829+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.821+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:03.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.109 seconds
[2025-11-12T04:40:03.982+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:03.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:03.987+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:03.987+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.054+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:04.046+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:04.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.142 seconds
[2025-11-12T04:40:04.180+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:04.184+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:04.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.221+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:04.213+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:04.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T04:40:04.317+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:04.321+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:04.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.353+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:04.345+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/spark_batch_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_batch_dag.py", line 54, in <module>
    train_model = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 265, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: train_model). Invalid arguments were:
**kwargs: {'pull_policy': 'Never'}
[2025-11-12T04:40:04.354+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:04.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.101 seconds
[2025-11-12T04:40:07.414+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:07.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:07.425+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:07.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:07.555+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:07.932+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:07.931+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:40:07.981+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:07.981+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:40:08.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.629 seconds
[2025-11-12T04:40:08.104+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:08.107+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.107+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.145+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.169+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.169+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:40:08.209+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.209+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:40:08.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.171 seconds
[2025-11-12T04:40:08.349+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:08.353+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.393+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.415+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.415+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:40:08.465+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.465+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:40:08.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.188 seconds
[2025-11-12T04:40:08.599+0000] {processor.py:161} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:08.603+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.640+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:08.660+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.660+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:40:08.695+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:08.694+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:40:08.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.167 seconds
[2025-11-12T04:40:52.430+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:52.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:40:52.433+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:52.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:52.477+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:40:52.510+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:52.510+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:40:52.544+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:40:52.543+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:40:52.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.147 seconds
[2025-11-12T04:41:23.624+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:23.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:41:23.629+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:23.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:23.672+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:23.976+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:23.976+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:41:24.013+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:24.012+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:41:24.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.437 seconds
[2025-11-12T04:41:54.272+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:54.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:41:54.277+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:54.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:54.319+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:41:54.363+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:54.362+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:41:54.404+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:41:54.404+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:41:54.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.210 seconds
[2025-11-12T04:42:24.878+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:24.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:42:24.882+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:24.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:24.916+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:24.961+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:24.960+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:42:25.000+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:24.999+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:42:25.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.195 seconds
[2025-11-12T04:42:55.684+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:55.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:42:55.689+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:55.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:55.729+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:42:55.778+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:55.777+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:42:55.815+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:42:55.815+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:42:55.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.202 seconds
[2025-11-12T04:43:26.380+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:26.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:43:26.385+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:26.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:26.423+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:26.472+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:26.471+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:43:26.514+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:26.513+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:43:26.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.209 seconds
[2025-11-12T04:43:57.416+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:57.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:43:57.420+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:57.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:57.452+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:43:57.489+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:57.489+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:43:57.527+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:43:57.526+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:43:57.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.148 seconds
[2025-11-12T04:44:28.131+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:28.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:44:28.135+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:28.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:28.168+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:28.209+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:28.208+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:44:28.245+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:28.245+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:44:28.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.179 seconds
[2025-11-12T04:44:56.917+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:56.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:44:56.919+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:56.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:56.949+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:44:57.004+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:57.003+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:44:57.037+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:44:57.037+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:44:57.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.185 seconds
[2025-11-12T04:45:27.174+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:27.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:45:27.178+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:27.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:27.216+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:27.299+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:27.298+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:45:27.347+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:27.347+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:45:27.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.243 seconds
[2025-11-12T04:45:57.983+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:57.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:45:57.987+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:57.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:58.025+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:45:58.083+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:58.083+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:45:58.121+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:45:58.120+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:45:58.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.219 seconds
[2025-11-12T04:46:28.745+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:46:28.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:46:28.750+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:46:28.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:46:28.788+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:46:28.833+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:46:28.832+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:46:28.871+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:46:28.871+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:46:28.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.199 seconds
[2025-11-12T04:49:20.000+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:20.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:49:20.005+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:20.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:20.051+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:20.090+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:20.090+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:49:20.127+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:20.127+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:49:20.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.163 seconds
[2025-11-12T04:49:50.247+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:50.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:49:50.251+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:50.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:50.295+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:49:50.562+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:50.562+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:49:50.597+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:49:50.597+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:49:50.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.390 seconds
[2025-11-12T04:50:20.977+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:20.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:50:20.981+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:20.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:21.015+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:21.057+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:21.057+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:50:21.095+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:21.095+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:50:21.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.186 seconds
[2025-11-12T04:50:51.664+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:51.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:50:51.668+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:51.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:51.714+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:50:51.762+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:51.761+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:50:51.799+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:50:51.799+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:50:51.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.181 seconds
[2025-11-12T04:51:22.038+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:22.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:51:22.041+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:22.041+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:22.078+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:22.123+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:22.122+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:51:22.172+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:22.172+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:51:22.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.175 seconds
[2025-11-12T04:51:52.707+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:52.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:51:52.712+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:52.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:52.760+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:51:52.810+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:52.810+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:51:52.849+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:51:52.849+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:51:52.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.220 seconds
[2025-11-12T04:52:23.670+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:52:23.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:52:23.674+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:52:23.673+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:52:23.707+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:52:23.749+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:52:23.749+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:52:23.784+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:52:23.784+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:52:23.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.153 seconds
[2025-11-12T04:53:21.593+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:21.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:53:21.598+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:21.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:21.649+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:21.688+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:21.688+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:53:21.749+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:21.749+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:53:21.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.281 seconds
[2025-11-12T04:53:52.226+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:52.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:53:52.230+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:52.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:52.274+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:53:52.587+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:52.586+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:53:52.621+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:53:52.620+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:53:52.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.471 seconds
[2025-11-12T04:54:23.202+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:23.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:54:23.206+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:23.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:23.243+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:23.292+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:23.291+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:54:23.329+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:23.329+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:54:23.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.200 seconds
[2025-11-12T04:54:53.632+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:53.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:54:53.635+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:53.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:53.657+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:54:53.685+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:53.685+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:54:53.712+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:54:53.712+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:54:53.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.107 seconds
[2025-11-12T04:55:24.725+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:24.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:55:24.729+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:24.728+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:24.828+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:24.874+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:24.874+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:55:24.914+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:24.913+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:55:24.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.260 seconds
[2025-11-12T04:55:55.745+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:55.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:55:55.749+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:55.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:55.789+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:55:55.835+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:55.835+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:55:55.875+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:55:55.874+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:55:55.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.170 seconds
[2025-11-12T04:56:26.966+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:26.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:56:26.974+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:26.973+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:27.008+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:27.056+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:27.056+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:56:27.095+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:27.095+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:56:27.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.175 seconds
[2025-11-12T04:56:57.615+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:57.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:56:57.618+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:57.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:57.650+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:56:57.696+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:57.695+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:56:57.736+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:56:57.735+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:56:57.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.164 seconds
[2025-11-12T04:57:28.001+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:28.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:57:28.006+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:28.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:28.044+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:28.091+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:28.090+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:57:28.129+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:28.128+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:57:28.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.200 seconds
[2025-11-12T04:57:59.177+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:59.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:57:59.180+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:59.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:59.213+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:57:59.261+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:59.261+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:57:59.297+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:57:59.297+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:57:59.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.158 seconds
[2025-11-12T04:58:29.852+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:58:29.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T04:58:29.856+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:58:29.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:58:29.890+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T04:58:29.935+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:58:29.934+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T04:58:29.971+0000] {logging_mixin.py:188} INFO - [2025-11-12T04:58:29.971+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T04:58:30.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.158 seconds
[2025-11-12T13:45:28.351+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:28.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:45:28.353+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:28.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:28.381+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:28.404+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:28.404+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:45:28.432+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:28.432+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:45:28.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.111 seconds
[2025-11-12T13:45:59.322+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:59.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:45:59.323+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:59.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:59.342+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:45:59.509+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:59.509+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:45:59.530+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:45:59.530+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:45:59.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.232 seconds
[2025-11-12T13:46:30.342+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:46:30.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:46:30.344+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:46:30.344+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:46:30.359+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:46:30.381+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:46:30.381+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:46:30.400+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:46:30.400+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:46:30.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T13:47:01.241+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:01.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:47:01.242+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:01.242+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:01.258+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:01.280+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:01.280+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:47:01.299+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:01.299+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:47:01.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T13:47:32.196+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:32.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:47:32.197+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:32.197+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:32.214+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:47:32.234+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:32.233+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:47:32.252+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:47:32.251+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:47:32.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T13:48:03.052+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:03.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:48:03.054+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:03.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:03.068+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:03.089+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:03.088+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:48:03.107+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:03.107+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:48:03.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T13:48:34.092+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:34.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:48:34.094+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:34.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:34.109+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:48:34.131+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:34.131+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:48:34.150+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:48:34.149+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:48:34.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T13:49:05.053+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:05.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:49:05.054+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:05.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:05.068+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:05.089+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:05.089+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:49:05.107+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:05.107+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:49:05.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T13:49:36.000+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:36.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:49:36.002+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:36.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:36.017+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:49:36.038+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:36.038+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:49:36.056+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:49:36.055+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:49:36.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T13:50:06.697+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:06.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:50:06.698+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:06.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:06.714+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:06.735+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:06.735+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:50:06.754+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:06.754+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:50:06.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T13:50:37.669+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:37.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:50:37.671+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:37.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:37.687+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:50:37.709+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:37.708+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:50:37.726+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:50:37.726+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:50:37.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T13:51:08.577+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:08.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:51:08.579+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:08.578+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:08.593+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:08.613+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:08.612+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:51:08.630+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:08.630+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:51:08.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T13:51:39.536+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:39.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:51:39.538+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:39.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:39.553+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:51:39.572+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:39.572+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:51:39.590+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:51:39.590+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:51:39.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T13:52:10.403+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:10.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:52:10.405+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:10.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:10.420+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:10.442+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:10.442+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:52:10.459+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:10.459+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:52:10.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T13:52:41.418+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:41.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:52:41.420+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:41.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:41.436+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:52:41.458+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:41.458+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:52:41.477+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:52:41.477+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:52:41.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T13:53:12.291+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:12.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:53:12.293+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:12.293+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:12.310+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:12.335+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:12.335+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:53:12.355+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:12.355+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:53:12.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T13:53:43.248+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:43.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:53:43.250+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:43.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:43.264+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:53:43.284+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:43.284+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:53:43.302+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:53:43.301+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:53:43.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T13:54:14.066+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:14.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:54:14.068+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:14.067+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:14.085+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:14.109+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:14.109+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:54:14.130+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:14.130+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:54:14.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.085 seconds
[2025-11-12T13:54:44.814+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:44.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:54:44.816+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:44.816+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:44.833+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:54:44.856+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:44.856+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:54:44.875+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:54:44.875+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:54:44.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T13:55:15.654+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:15.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:55:15.656+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:15.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:15.675+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:15.696+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:15.696+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:55:15.715+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:15.715+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:55:15.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T13:55:46.699+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:46.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:55:46.701+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:46.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:46.716+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:55:46.739+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:46.738+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:55:46.758+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:55:46.758+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:55:46.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T13:56:17.644+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:17.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:56:17.645+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:17.645+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:17.661+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:17.684+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:17.684+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:56:17.704+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:17.704+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:56:17.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T13:56:48.540+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:48.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:56:48.541+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:48.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:48.558+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:56:48.581+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:48.581+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:56:48.600+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:56:48.600+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:56:48.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T13:57:19.561+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:19.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:57:19.563+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:19.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:19.580+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:19.604+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:19.604+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:57:19.623+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:19.623+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:57:19.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T13:57:50.482+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:50.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:57:50.484+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:50.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:50.500+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:57:50.521+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:50.521+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:57:50.540+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:57:50.540+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:57:50.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T13:58:21.476+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:21.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:58:21.477+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:21.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:21.492+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:21.511+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:21.511+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:58:21.530+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:21.529+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:58:21.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T13:58:52.161+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:52.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:58:52.163+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:52.162+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:52.179+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:58:52.203+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:52.203+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:58:52.221+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:58:52.220+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:58:52.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T13:59:23.090+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:23.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:59:23.092+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:23.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:23.106+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:23.127+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:23.126+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:59:23.147+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:23.147+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:59:23.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T13:59:54.141+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:54.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T13:59:54.143+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:54.143+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:54.159+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T13:59:54.182+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:54.182+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T13:59:54.202+0000] {logging_mixin.py:188} INFO - [2025-11-12T13:59:54.202+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T13:59:54.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T14:00:25.024+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:25.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:00:25.026+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:25.025+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:25.040+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:25.064+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:25.063+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:00:25.083+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:25.083+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:00:25.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:00:55.980+0000] {processor.py:161} INFO - Started process (PID=327) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:55.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:00:55.981+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:55.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:55.997+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:00:56.020+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:56.019+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:00:56.041+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:00:56.040+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:00:56.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.083 seconds
[2025-11-12T14:01:26.870+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:26.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:01:26.872+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:26.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:26.886+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:26.906+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:26.906+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:01:26.923+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:26.923+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:01:26.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.070 seconds
[2025-11-12T14:01:57.835+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:57.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:01:57.837+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:57.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:57.853+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:01:57.876+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:57.876+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:01:57.898+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:01:57.897+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:01:57.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.083 seconds
[2025-11-12T14:02:28.857+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:28.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:02:28.858+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:28.858+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:28.878+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:28.899+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:28.899+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:02:28.917+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:28.917+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:02:28.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:02:59.787+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:59.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:02:59.791+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:59.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:59.816+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:02:59.846+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:59.846+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:02:59.870+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:02:59.869+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:02:59.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.111 seconds
[2025-11-12T14:03:30.383+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:03:30.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:03:30.385+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:03:30.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:03:30.406+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:03:30.431+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:03:30.431+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:03:30.453+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:03:30.453+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:03:30.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.093 seconds
[2025-11-12T14:04:01.392+0000] {processor.py:161} INFO - Started process (PID=357) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:01.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:04:01.393+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:01.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:01.408+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:01.428+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:01.427+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:04:01.446+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:01.445+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:04:01.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T14:04:32.292+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:32.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:04:32.294+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:32.294+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:32.319+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:04:32.357+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:32.356+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:04:32.384+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:04:32.383+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:04:32.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.130 seconds
[2025-11-12T14:05:03.248+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:03.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:05:03.250+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:03.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:03.268+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:03.290+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:03.290+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:05:03.309+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:03.308+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:05:03.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T14:05:26.116+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:26.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:05:26.118+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:26.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:26.137+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:26.173+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:26.172+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:05:26.193+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:26.193+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:05:26.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.096 seconds
[2025-11-12T14:05:57.149+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:57.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:05:57.151+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:57.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:57.177+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:05:57.209+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:57.209+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:05:57.229+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:05:57.229+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:05:57.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.098 seconds
[2025-11-12T14:06:28.107+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:28.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:06:28.109+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:28.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:28.125+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:28.147+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:28.147+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:06:28.169+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:28.169+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:06:28.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T14:06:59.025+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:59.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:06:59.027+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:59.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:59.044+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:06:59.066+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:59.065+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:06:59.087+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:06:59.087+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:06:59.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T14:07:29.980+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:07:29.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:07:29.982+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:07:29.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:07:30.003+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:07:30.034+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:07:30.034+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:07:30.060+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:07:30.059+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:07:30.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.101 seconds
[2025-11-12T14:08:00.877+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:00.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:08:00.883+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:00.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:00.981+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:01.032+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:01.031+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:08:01.117+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:01.117+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:08:01.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.280 seconds
[2025-11-12T14:08:31.823+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:31.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:08:31.826+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:31.825+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:31.841+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:08:31.866+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:31.866+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:08:31.883+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:08:31.883+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:08:31.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:09:02.412+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:02.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:09:02.414+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:02.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:02.428+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:02.448+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:02.448+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:09:02.465+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:02.465+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:09:02.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T14:09:33.372+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:33.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:09:33.373+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:33.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:33.389+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:09:33.411+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:33.411+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:09:33.433+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:09:33.432+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:09:33.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:10:04.251+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:04.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:10:04.253+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:04.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:04.270+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:04.291+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:04.291+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:10:04.309+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:04.309+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:10:04.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T14:10:35.358+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:35.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:10:35.360+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:35.359+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:35.376+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:10:35.397+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:35.397+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:10:35.419+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:10:35.418+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:10:35.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:11:06.260+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:06.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:11:06.263+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:06.262+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:06.281+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:06.305+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:06.304+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:11:06.325+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:06.325+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:11:06.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T14:11:37.181+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:37.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:11:37.183+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:37.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:37.204+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:11:37.229+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:37.229+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:11:37.252+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:11:37.251+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:11:37.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.098 seconds
[2025-11-12T14:12:08.100+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:08.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:12:08.102+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:08.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:08.119+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:08.142+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:08.142+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:12:08.162+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:08.162+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:12:08.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T14:12:38.990+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:38.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:12:38.991+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:38.991+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:39.005+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:12:39.024+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:39.024+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:12:39.048+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:12:39.048+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:12:39.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:13:09.658+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:09.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:13:09.660+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:09.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:09.676+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:09.698+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:09.697+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:13:09.718+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:09.718+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:13:09.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T14:13:40.593+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:40.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:13:40.596+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:40.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:40.614+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:13:40.641+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:40.640+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:13:40.663+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:13:40.663+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:13:40.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T14:14:11.507+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:11.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:14:11.510+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:11.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:11.528+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:11.550+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:11.549+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:14:11.570+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:11.570+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:14:11.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.093 seconds
[2025-11-12T14:14:42.424+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:42.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:14:42.426+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:42.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:42.441+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:14:42.462+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:42.462+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:14:42.481+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:14:42.481+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:14:42.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T14:15:13.335+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:13.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:15:13.337+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:13.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:13.355+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:13.378+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:13.378+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:15:13.398+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:13.398+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:15:13.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.084 seconds
[2025-11-12T14:15:44.301+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:44.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:15:44.303+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:44.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:44.323+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:15:44.347+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:44.347+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:15:44.368+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:15:44.368+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:15:44.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.085 seconds
[2025-11-12T14:16:15.214+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:15.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:16:15.216+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:15.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:15.232+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:15.253+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:15.253+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:16:15.272+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:15.272+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:16:15.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T14:16:46.293+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:46.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:16:46.294+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:46.294+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:46.310+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:16:46.332+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:46.332+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:16:46.350+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:16:46.349+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:16:46.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T14:17:17.238+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:17.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:17:17.239+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:17.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:17.258+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:17.283+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:17.283+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:17:17.308+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:17.307+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:17:17.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.093 seconds
[2025-11-12T14:17:47.897+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:47.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:17:47.899+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:47.898+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:47.915+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:17:47.937+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:47.936+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:17:47.958+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:17:47.958+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:17:47.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T14:18:18.047+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:18.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:18:18.049+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:18.049+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:18.067+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:18.090+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:18.089+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:18:18.109+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:18.109+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:18:18.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:18:49.084+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:49.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:18:49.086+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:49.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:49.100+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:18:49.123+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:49.122+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:18:49.143+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:18:49.143+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:18:49.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T14:19:20.036+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:20.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:19:20.038+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:20.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:20.057+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:20.087+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:20.087+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:19:20.113+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:20.112+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:19:20.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.102 seconds
[2025-11-12T14:19:51.023+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:51.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:19:51.025+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:51.025+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:51.040+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:19:51.061+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:51.061+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:19:51.079+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:19:51.079+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:19:51.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T14:20:22.066+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:22.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:20:22.068+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:22.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:22.085+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:22.106+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:22.106+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:20:22.125+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:22.124+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:20:22.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:20:53.010+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:53.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:20:53.012+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:53.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:53.026+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:20:53.048+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:53.048+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:20:53.067+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:20:53.067+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:20:53.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T14:21:23.123+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:23.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:21:23.125+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:23.125+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:23.140+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:23.161+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:23.161+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:21:23.179+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:23.179+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:21:23.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T14:21:54.054+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:54.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:21:54.057+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:54.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:54.074+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:21:54.096+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:54.096+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:21:54.117+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:21:54.117+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:21:54.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T14:22:24.712+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:24.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:22:24.714+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:24.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:24.732+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:24.757+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:24.757+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:22:24.779+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:24.778+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:22:24.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T14:22:55.624+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:55.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:22:55.627+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:55.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:55.644+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:22:55.665+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:55.665+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:22:55.688+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:22:55.687+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:22:55.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.091 seconds
[2025-11-12T14:23:25.879+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:25.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:23:25.881+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:25.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:25.897+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:25.920+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:25.920+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:23:25.943+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:25.943+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:23:25.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T14:23:56.632+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:56.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:23:56.634+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:56.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:56.658+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:23:56.686+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:56.686+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:23:56.717+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:23:56.716+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:23:56.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.112 seconds
[2025-11-12T14:24:27.591+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:27.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:24:27.593+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:27.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:27.610+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:27.632+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:27.631+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:24:27.654+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:27.653+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:24:27.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T14:24:58.483+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:58.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:24:58.485+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:58.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:58.501+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:24:58.524+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:58.523+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:24:58.542+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:24:58.542+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:24:58.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T14:25:29.411+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:25:29.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:25:29.413+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:25:29.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:25:29.430+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:25:29.450+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:25:29.450+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:25:29.468+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:25:29.468+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:25:29.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:26:00.458+0000] {processor.py:161} INFO - Started process (PID=379) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:00.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:26:00.461+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:00.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:00.488+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:00.522+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:00.522+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:26:00.544+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:00.544+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:26:00.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.109 seconds
[2025-11-12T14:26:31.414+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:31.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:26:31.416+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:31.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:31.432+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:26:31.454+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:31.454+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:26:31.474+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:26:31.474+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:26:31.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:27:02.122+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:02.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:27:02.125+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:02.124+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:02.151+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:02.180+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:02.179+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:27:02.200+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:02.199+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:27:02.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.097 seconds
[2025-11-12T14:27:33.010+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:33.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:27:33.012+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:33.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:33.027+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:27:33.048+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:33.048+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:27:33.067+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:27:33.067+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:27:33.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T14:28:03.986+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:03.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:28:03.988+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:03.987+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:04.002+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:04.024+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:04.023+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:28:04.043+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:04.043+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:28:04.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T14:28:34.886+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:34.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:28:34.888+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:34.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:34.906+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:28:34.931+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:34.930+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:28:34.951+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:28:34.951+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:28:34.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T14:29:05.815+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:05.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:29:05.817+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:05.817+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:05.836+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:05.859+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:05.858+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:29:05.879+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:05.879+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:29:05.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T14:29:36.751+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:36.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:29:36.754+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:36.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:36.771+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:29:36.794+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:36.794+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:29:36.817+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:29:36.816+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:29:36.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.095 seconds
[2025-11-12T14:30:07.684+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:07.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:30:07.687+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:07.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:07.712+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:07.747+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:07.747+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:30:07.766+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:07.766+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:30:07.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.104 seconds
[2025-11-12T14:30:38.612+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:38.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:30:38.613+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:38.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:38.628+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:30:38.649+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:38.649+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:30:38.668+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:30:38.668+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:30:38.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:31:09.598+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:31:09.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:31:09.600+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:31:09.599+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:31:09.626+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:31:09.656+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:31:09.656+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:31:09.677+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:31:09.677+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:31:09.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.103 seconds
[2025-11-12T14:32:20.577+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:20.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:32:20.580+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:20.579+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:20.612+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:20.637+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:20.637+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:32:20.666+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:20.666+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:32:20.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.116 seconds
[2025-11-12T14:32:51.548+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:51.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:32:51.550+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:51.550+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:51.568+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:32:51.722+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:51.721+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:32:51.739+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:32:51.739+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:32:51.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.214 seconds
[2025-11-12T14:37:36.999+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:37:37.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:37:37.002+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:37:37.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:37:37.030+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:37:37.049+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:37:37.049+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:37:37.072+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:37:37.072+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:37:37.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.095 seconds
[2025-11-12T14:38:07.678+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:07.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:38:07.680+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:07.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:07.699+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:07.841+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:07.841+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:38:07.858+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:07.857+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:38:07.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.199 seconds
[2025-11-12T14:38:38.633+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:38.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:38:38.635+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:38.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:38.654+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:38:38.673+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:38.673+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:38:38.689+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:38:38.689+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:38:38.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T14:39:09.547+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:09.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:39:09.550+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:09.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:09.568+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:09.590+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:09.590+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:39:09.609+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:09.609+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:39:09.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T14:39:40.480+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:40.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:39:40.483+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:40.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:40.501+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:39:40.524+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:40.524+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:39:40.545+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:39:40.545+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:39:40.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T14:40:11.404+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:11.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:40:11.406+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:11.406+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:11.421+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:11.441+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:11.440+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:40:11.458+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:11.458+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:40:11.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T14:40:42.388+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:42.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:40:42.390+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:42.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:42.406+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:40:42.426+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:42.425+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:40:42.445+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:40:42.445+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:40:42.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T14:41:13.350+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:13.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:41:13.351+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:13.351+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:13.368+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:13.390+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:13.390+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:41:13.409+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:13.409+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:41:13.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:41:44.195+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:44.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:41:44.197+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:44.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:44.214+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:41:44.236+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:44.236+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:41:44.255+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:41:44.255+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:41:44.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T14:42:14.866+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:14.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:42:14.867+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:14.867+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:14.882+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:14.900+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:14.899+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:42:14.917+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:14.917+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:42:14.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T14:42:45.893+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:45.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:42:45.895+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:45.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:45.911+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:42:45.931+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:45.931+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:42:45.949+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:42:45.949+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:42:45.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T14:43:16.828+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:16.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:43:16.829+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:16.829+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:16.844+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:16.866+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:16.865+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:43:16.884+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:16.884+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:43:16.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.079 seconds
[2025-11-12T14:43:47.746+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:47.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:43:47.749+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:47.748+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:47.766+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:43:47.789+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:47.788+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:43:47.810+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:43:47.809+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:43:47.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.085 seconds
[2025-11-12T14:44:18.635+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:18.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:44:18.637+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:18.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:18.650+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:18.669+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:18.669+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:44:18.686+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:18.686+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:44:18.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T14:44:49.611+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:49.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:44:49.617+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:49.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:49.652+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:44:49.698+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:49.697+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:44:49.741+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:44:49.740+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:44:49.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.169 seconds
[2025-11-12T14:45:20.478+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:20.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:45:20.480+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:20.480+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:20.502+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:20.544+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:20.543+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:45:20.580+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:20.580+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:45:20.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.128 seconds
[2025-11-12T14:45:51.365+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:51.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:45:51.368+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:51.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:51.387+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:45:51.412+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:51.412+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:45:51.446+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:45:51.445+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:45:51.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.108 seconds
[2025-11-12T14:46:22.386+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:22.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:46:22.389+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:22.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:22.408+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:22.434+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:22.434+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:46:22.459+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:22.458+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:46:22.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.099 seconds
[2025-11-12T14:46:53.020+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:53.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:46:53.024+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:53.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:53.088+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:46:53.141+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:53.140+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:46:53.228+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:46:53.228+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:46:53.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.256 seconds
[2025-11-12T14:47:23.936+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:23.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:47:23.938+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:23.938+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:23.956+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:23.980+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:23.979+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:47:24.002+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:24.001+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:47:24.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T14:47:54.844+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:54.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:47:54.846+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:54.846+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:54.864+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:47:54.888+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:54.888+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:47:54.910+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:47:54.910+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:47:54.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T14:48:25.763+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:25.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:48:25.764+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:25.764+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:25.782+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:25.803+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:25.802+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:48:25.820+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:25.820+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:48:25.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.075 seconds
[2025-11-12T14:48:56.718+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:56.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:48:56.720+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:56.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:56.733+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:48:56.752+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:56.752+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:48:56.771+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:48:56.771+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:48:56.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.069 seconds
[2025-11-12T14:49:27.614+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:27.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:49:27.616+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:27.615+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:27.630+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:27.650+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:27.650+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:49:27.668+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:27.668+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:49:27.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T14:49:58.499+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:58.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:49:58.501+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:58.500+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:58.515+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:49:58.535+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:58.535+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:49:58.555+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:49:58.555+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:49:58.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T14:50:29.444+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:50:29.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:50:29.446+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:50:29.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:50:29.462+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:50:29.485+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:50:29.484+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:50:29.506+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:50:29.505+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:50:29.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T14:51:00.437+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:00.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:51:00.439+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:00.438+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:00.453+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:00.474+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:00.474+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:51:00.492+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:00.492+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:51:00.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T14:51:31.007+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:31.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:51:31.010+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:31.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:31.027+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:51:31.050+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:31.049+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:51:31.070+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:51:31.070+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:51:31.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T14:52:01.887+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:01.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:52:01.889+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:01.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:01.906+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:01.930+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:01.930+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:52:01.951+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:01.951+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:52:01.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.084 seconds
[2025-11-12T14:52:32.807+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:32.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:52:32.809+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:32.809+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:32.827+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:52:32.848+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:32.848+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:52:32.867+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:52:32.866+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:52:32.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T14:53:03.716+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:03.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:53:03.718+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:03.718+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:03.734+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:03.758+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:03.758+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:53:03.780+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:03.780+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:53:03.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T14:53:34.615+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:34.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:53:34.617+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:34.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:34.637+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:53:34.660+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:34.659+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:53:34.678+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:53:34.678+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:53:34.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.083 seconds
[2025-11-12T14:54:05.495+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:05.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:54:05.498+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:05.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:05.521+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:05.558+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:05.558+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:54:05.584+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:05.584+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:54:05.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.110 seconds
[2025-11-12T14:54:36.420+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:36.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:54:36.423+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:36.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:36.440+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:54:36.468+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:36.468+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:54:36.488+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:54:36.488+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:54:36.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T14:55:07.382+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:07.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:55:07.384+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:07.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:07.401+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:07.420+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:07.420+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:55:07.438+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:07.438+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:55:07.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T14:55:38.043+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:38.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:55:38.045+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:38.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:38.061+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:55:38.081+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:38.081+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:55:38.100+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:55:38.100+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:55:38.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T14:56:08.951+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:08.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:56:08.953+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:08.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:08.969+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:08.992+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:08.992+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:56:09.012+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:09.012+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:56:09.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T14:56:39.846+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:39.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:56:39.849+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:39.848+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:39.873+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:56:39.899+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:39.899+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:56:39.922+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:56:39.921+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:56:39.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.100 seconds
[2025-11-12T14:57:10.785+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:10.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:57:10.787+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:10.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:10.806+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:10.829+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:10.828+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:57:10.850+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:10.850+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:57:10.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T14:57:41.698+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:41.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:57:41.700+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:41.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:41.722+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:57:41.757+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:41.757+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:57:41.780+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:57:41.779+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:57:41.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.104 seconds
[2025-11-12T14:58:12.564+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:12.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:58:12.566+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:12.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:12.582+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:12.604+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:12.604+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:58:12.624+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:12.624+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:58:12.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.084 seconds
[2025-11-12T14:58:43.529+0000] {processor.py:161} INFO - Started process (PID=385) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:43.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:58:43.531+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:43.531+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:43.549+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:58:43.573+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:43.572+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:58:43.592+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:58:43.592+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:58:43.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.083 seconds
[2025-11-12T14:59:14.485+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:14.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:59:14.487+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:14.486+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:14.503+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:14.532+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:14.532+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:59:14.560+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:14.560+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:59:14.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.103 seconds
[2025-11-12T14:59:45.372+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:45.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T14:59:45.374+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:45.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:45.392+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T14:59:45.417+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:45.417+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T14:59:45.440+0000] {logging_mixin.py:188} INFO - [2025-11-12T14:59:45.439+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T14:59:45.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T15:00:16.030+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:16.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:00:16.032+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:16.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:16.046+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:16.065+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:16.065+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:00:16.083+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:16.083+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:00:16.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T15:00:46.994+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:46.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:00:46.996+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:46.996+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:47.014+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:00:47.036+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:47.036+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:00:47.057+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:00:47.056+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:00:47.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.084 seconds
[2025-11-12T15:01:17.905+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:17.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:01:17.906+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:17.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:17.924+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:17.947+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:17.947+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:01:17.967+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:17.967+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:01:17.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T15:01:48.844+0000] {processor.py:161} INFO - Started process (PID=415) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:48.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:01:48.845+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:48.845+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:48.860+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:01:48.881+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:48.881+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:01:48.899+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:01:48.899+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:01:48.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:02:19.663+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:19.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:02:19.665+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:19.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:19.681+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:19.704+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:19.704+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:02:19.723+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:19.723+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:02:19.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:02:50.683+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:50.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:02:50.686+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:50.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:50.705+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:02:50.730+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:50.730+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:02:50.751+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:02:50.750+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:02:50.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T15:03:21.617+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:21.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:03:21.619+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:21.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:21.638+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:21.664+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:21.664+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:03:21.688+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:21.687+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:03:21.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.093 seconds
[2025-11-12T15:03:52.565+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:52.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:03:52.567+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:52.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:52.581+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:03:52.600+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:52.600+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:03:52.620+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:03:52.619+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:03:52.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:04:23.616+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:23.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:04:23.618+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:23.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:23.634+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:23.657+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:23.656+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:04:23.678+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:23.678+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:04:23.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T15:04:54.142+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:54.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:04:54.144+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:54.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:54.162+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:04:54.186+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:54.186+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:04:54.206+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:04:54.206+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:04:54.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T15:05:25.078+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:25.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:05:25.080+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:25.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:25.096+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:25.118+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:25.118+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:05:25.136+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:25.136+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:05:25.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T15:05:56.124+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:56.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:05:56.126+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:56.125+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:56.141+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:05:56.161+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:56.161+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:05:56.180+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:05:56.180+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:05:56.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T15:06:27.029+0000] {processor.py:161} INFO - Started process (PID=460) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:27.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:06:27.031+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:27.030+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:27.046+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:27.067+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:27.067+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:06:27.086+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:27.086+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:06:27.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:06:57.937+0000] {processor.py:161} INFO - Started process (PID=465) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:57.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:06:57.939+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:57.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:57.957+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:06:57.982+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:57.981+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:06:58.003+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:06:58.003+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:06:58.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.088 seconds
[2025-11-12T15:07:28.859+0000] {processor.py:161} INFO - Started process (PID=470) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:28.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:07:28.860+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:28.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:28.879+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:28.903+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:28.903+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:07:28.925+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:28.925+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:07:28.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.086 seconds
[2025-11-12T15:07:59.792+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:59.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:07:59.794+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:59.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:59.811+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:07:59.833+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:59.832+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:07:59.852+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:07:59.851+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:07:59.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T15:08:30.742+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:08:30.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:08:30.744+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:08:30.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:08:30.762+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:08:30.787+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:08:30.786+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:08:30.820+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:08:30.820+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:08:30.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.109 seconds
[2025-11-12T15:09:01.487+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:01.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:09:01.488+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:01.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:01.505+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:01.528+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:01.528+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:09:01.548+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:01.548+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:09:01.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:09:32.365+0000] {processor.py:161} INFO - Started process (PID=490) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:32.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:09:32.367+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:32.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:32.387+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:09:32.413+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:32.412+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:09:32.434+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:09:32.434+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:09:32.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.090 seconds
[2025-11-12T15:10:03.376+0000] {processor.py:161} INFO - Started process (PID=495) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:03.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:10:03.379+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:03.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:03.402+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:03.434+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:03.433+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:10:03.465+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:03.465+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:10:03.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.117 seconds
[2025-11-12T15:10:34.318+0000] {processor.py:161} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:34.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:10:34.320+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:34.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:34.335+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:10:34.359+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:34.359+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:10:34.379+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:10:34.379+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:10:34.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:11:05.291+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:05.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:11:05.292+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:05.292+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:05.309+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:05.329+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:05.329+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:11:05.346+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:05.346+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:11:05.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T15:11:36.246+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:36.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:11:36.248+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:36.248+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:36.265+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:11:36.287+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:36.287+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:11:36.307+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:11:36.307+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:11:36.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:12:07.179+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:07.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:12:07.180+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:07.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:07.195+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:07.214+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:07.214+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:12:07.231+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:07.230+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:12:07.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.068 seconds
[2025-11-12T15:12:38.092+0000] {processor.py:161} INFO - Started process (PID=520) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:38.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:12:38.094+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:38.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:38.108+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:12:38.127+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:38.127+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:12:38.144+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:12:38.144+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:12:38.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.068 seconds
[2025-11-12T15:13:09.005+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:09.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:13:09.007+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:09.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:09.022+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:09.043+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:09.043+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:13:09.062+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:09.062+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:13:09.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:13:39.739+0000] {processor.py:161} INFO - Started process (PID=530) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:39.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:13:39.741+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:39.740+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:39.756+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:13:39.777+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:39.777+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:13:39.796+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:13:39.796+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:13:39.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:14:10.687+0000] {processor.py:161} INFO - Started process (PID=535) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:10.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:14:10.689+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:10.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:10.703+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:10.721+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:10.721+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:14:10.740+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:10.740+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:14:10.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.071 seconds
[2025-11-12T15:14:41.622+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:41.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:14:41.624+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:41.624+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:41.638+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:14:41.658+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:41.658+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:14:41.675+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:14:41.675+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:14:41.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T15:15:12.533+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:12.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:15:12.535+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:12.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:12.549+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:12.568+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:12.568+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:15:12.585+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:12.585+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:15:12.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T15:15:43.601+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:43.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:15:43.603+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:43.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:43.617+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:15:43.636+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:43.636+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:15:43.653+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:15:43.652+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:15:43.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.070 seconds
[2025-11-12T15:16:14.570+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:14.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:16:14.572+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:14.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:14.589+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:14.609+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:14.609+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:16:14.630+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:14.629+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:16:14.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:16:45.505+0000] {processor.py:161} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:45.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:16:45.507+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:45.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:45.525+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:16:45.548+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:45.548+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:16:45.569+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:16:45.569+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:16:45.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.087 seconds
[2025-11-12T15:17:16.467+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:16.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:17:16.468+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:16.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:16.485+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:16.506+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:16.506+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:17:16.526+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:16.526+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:17:16.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.077 seconds
[2025-11-12T15:17:47.151+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:47.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:17:47.153+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:47.153+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:47.171+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:17:47.195+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:47.194+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:17:47.218+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:17:47.218+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:17:47.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.094 seconds
[2025-11-12T15:18:18.082+0000] {processor.py:161} INFO - Started process (PID=575) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:18.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:18:18.085+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:18.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:18.103+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:18.127+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:18.127+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:18:18.149+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:18.148+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:18:18.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.089 seconds
[2025-11-12T15:18:49.019+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:49.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:18:49.021+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:49.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:49.038+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:18:49.061+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:49.061+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:18:49.081+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:18:49.080+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:18:49.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T15:19:19.902+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:19.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:19:19.904+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:19.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:19.919+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:19.943+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:19.943+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:19:19.962+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:19.962+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:19:19.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T15:19:50.836+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:50.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:19:50.838+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:50.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:50.853+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:19:50.874+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:50.874+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:19:50.893+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:19:50.893+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:19:50.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:20:21.779+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:21.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:20:21.781+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:21.781+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:21.799+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:21.821+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:21.820+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:20:21.841+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:21.841+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:20:21.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T15:20:52.688+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:52.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:20:52.690+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:52.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:52.705+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:20:52.727+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:52.726+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:20:52.744+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:20:52.744+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:20:52.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T15:21:23.654+0000] {processor.py:161} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:23.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:21:23.656+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:23.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:23.670+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:23.691+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:23.691+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:21:23.710+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:23.710+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:21:23.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:21:54.570+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:54.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:21:54.572+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:54.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:54.586+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:21:54.606+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:54.606+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:21:54.625+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:21:54.625+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:21:54.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T15:22:25.276+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:25.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:22:25.278+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:25.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:25.294+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:25.317+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:25.316+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:22:25.335+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:25.335+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:22:25.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:22:56.217+0000] {processor.py:161} INFO - Started process (PID=620) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:56.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:22:56.218+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:56.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:56.233+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:22:56.252+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:56.252+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:22:56.269+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:22:56.269+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:22:56.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.072 seconds
[2025-11-12T15:23:27.121+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:27.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:23:27.124+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:27.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:27.139+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:27.160+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:27.160+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:23:27.178+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:27.178+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:23:27.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.074 seconds
[2025-11-12T15:23:58.070+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:58.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:23:58.072+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:58.071+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:58.086+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:23:58.110+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:58.110+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:23:58.135+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:23:58.134+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:23:58.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.090 seconds
[2025-11-12T15:24:29.128+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:24:29.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:24:29.130+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:24:29.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:24:29.155+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:24:29.188+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:24:29.188+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:24:29.215+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:24:29.214+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:24:29.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.122 seconds
[2025-11-12T15:25:00.123+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:00.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:25:00.125+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:00.124+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:00.140+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:00.164+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:00.164+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:25:00.185+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:00.185+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:25:00.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.083 seconds
[2025-11-12T15:25:31.094+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:31.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:25:31.097+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:31.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:31.122+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:25:31.159+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:31.159+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:25:31.188+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:25:31.188+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:25:31.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.128 seconds
[2025-11-12T15:26:02.064+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:02.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:26:02.066+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:02.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:02.087+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:02.114+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:02.114+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:26:02.136+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:02.136+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:26:02.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.096 seconds
[2025-11-12T15:26:33.124+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:33.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:26:33.126+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:33.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:33.142+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:26:33.164+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:33.164+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:26:33.182+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:26:33.182+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:26:33.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.076 seconds
[2025-11-12T15:27:03.688+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:03.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:27:03.690+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:03.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:03.708+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:03.732+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:03.732+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:27:03.759+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:03.759+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:27:03.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.094 seconds
[2025-11-12T15:27:34.546+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:34.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:27:34.548+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:34.547+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:34.564+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:27:34.588+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:34.587+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:27:34.607+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:27:34.607+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:27:34.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.078 seconds
[2025-11-12T15:28:05.520+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:05.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:28:05.522+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:05.521+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:05.537+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:05.561+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:05.561+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:28:05.582+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:05.582+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:28:05.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.081 seconds
[2025-11-12T15:28:36.448+0000] {processor.py:161} INFO - Started process (PID=675) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:36.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:28:36.451+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:36.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:36.471+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:28:36.500+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:36.500+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:28:36.523+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:28:36.523+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:28:36.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.104 seconds
[2025-11-12T15:29:07.385+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:07.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:29:07.391+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:07.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:07.407+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:07.431+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:07.430+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:29:07.451+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:07.451+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:29:07.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.092 seconds
[2025-11-12T15:29:38.350+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:38.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:29:38.352+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:38.351+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:38.371+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:29:38.397+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:38.397+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:29:38.421+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:29:38.421+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:29:38.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.095 seconds
[2025-11-12T15:30:09.236+0000] {processor.py:161} INFO - Started process (PID=690) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:09.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:30:09.238+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:09.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:09.255+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:09.280+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:09.280+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:30:09.301+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:09.301+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:30:09.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.082 seconds
[2025-11-12T15:30:40.193+0000] {processor.py:161} INFO - Started process (PID=695) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:40.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:30:40.195+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:40.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:40.210+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:30:40.230+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:40.230+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:30:40.249+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:30:40.249+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:30:40.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.073 seconds
[2025-11-12T15:31:10.780+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:10.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:31:10.782+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:10.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:10.798+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:10.818+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:10.818+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:31:10.836+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:10.836+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:31:10.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
[2025-11-12T15:31:41.700+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:41.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/spark_batch_dag.py for tasks to queue
[2025-11-12T15:31:41.702+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:41.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:41.717+0000] {processor.py:840} INFO - DAG(s) 'spark_batch_pipeline' retrieved from /opt/airflow/dags/spark_batch_dag.py
[2025-11-12T15:31:41.740+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:41.740+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-11-12T15:31:41.759+0000] {logging_mixin.py:188} INFO - [2025-11-12T15:31:41.759+0000] {dag.py:3823} INFO - Setting next_dagrun for spark_batch_pipeline to 2025-11-12 00:00:00+00:00, run_after=2025-11-13 00:00:00+00:00
[2025-11-12T15:31:41.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/spark_batch_dag.py took 0.080 seconds
